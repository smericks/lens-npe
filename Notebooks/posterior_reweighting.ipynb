{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import h5py\n",
    "import corner\n",
    "from matplotlib.lines import Line2D\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/smericks/Desktop/StrongLensing/lens-npe/')\n",
    "from Inference.network_reweighted_posteriors import NetworkReweightedPosteriors\n",
    "import visualization_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to re-weight NPE posteriors to account for \n",
    "distribution shift between the test set distribution and the training set \n",
    "distribution. \n",
    "We use the shifted test set for this example.\n",
    "\n",
    "Please note, as discussed in Erickson et al. '24, this technique currently produces \n",
    "miscalibrated (overconfident) posteriors, and is not recommended for application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_filepath = '../Paper/from_zenodo/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Network Predictions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NPE model predictions \n",
    "npe_preds_path = zenodo_filepath+'model_predictions/npe/diag/'\n",
    "\n",
    "# SHIFTED SET\n",
    "file_path = npe_preds_path+'narrow_predictions.h5'\n",
    "h5f = h5py.File(file_path, 'r')\n",
    "y_test_shifted = h5f.get('y_test').value\n",
    "y_pred_shifted = h5f.get('y_pred').value\n",
    "std_pred_shifted = h5f.get('std_pred').value\n",
    "prec_pred_shifted = h5f.get('prec_pred').value\n",
    "h5f.close()\n",
    "\n",
    "# DOPPELGANGER SET\n",
    "file_path = npe_preds_path+'doppelganger_predictions.h5'\n",
    "h5f = h5py.File(file_path, 'r')\n",
    "y_test_doppel = h5f.get('y_test').value\n",
    "y_pred_doppel = h5f.get('y_pred').value\n",
    "std_pred_doppel = h5f.get('std_pred').value\n",
    "prec_pred_doppel = h5f.get('prec_pred').value\n",
    "h5f.close()\n",
    "\n",
    "# SHIFTED SET\n",
    "y_pred_shifted_seq_list = np.load(zenodo_filepath+'model_predictions/snpe/shifted/y_pred_list_epoch10.npy')\n",
    "std_pred_shifted_seq_list = np.load(zenodo_filepath+'model_predictions/snpe/shifted/std_pred_list_epoch10.npy')\n",
    "prec_pred_shifted_seq_list = np.load(zenodo_filepath+'model_predictions/snpe/shifted/prec_pred_list_epoch10.npy')\n",
    "# DOPPELGANGER SET \n",
    "y_pred_doppel_seq_list = np.load(zenodo_filepath+'model_predictions/snpe/doppelganger/y_pred_list_epoch10.npy')\n",
    "std_pred_doppel_seq_list = np.load(zenodo_filepath+'model_predictions/snpe/doppelganger/std_pred_list_epoch10.npy')\n",
    "prec_pred_doppel_seq_list = np.load(zenodo_filepath+'model_predictions/snpe/doppelganger/prec_pred_list_epoch10.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifted Set Re-Weighting ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_computed = True\n",
    "debug = True\n",
    "\n",
    "if not debug and not already_computed:\n",
    "    print(\"WARNING: Running re-weighting on all 20 shifted set lenses takes over an hour.\")\n",
    "    print(\"Debug=True ensures this is run for only one lens\")\n",
    "\n",
    "seq_reweighted_filepath = zenodo_filepath+'model_predictions/snpe/shifted/reweighted_seq_shifted.h5'\n",
    "\n",
    "if already_computed == True:\n",
    "    samps_list_seq_shifted,weights_list_seq_shifted = NetworkReweightedPosteriors.load_samps_weights(seq_reweighted_filepath)\n",
    "\n",
    "else:\n",
    "    train_mean = [0.8,0.,0.,2.,0.,0,0.,0.,0.,0.]\n",
    "    train_scatter = [0.15,.12,0.12,0.2,0.2,0.2,0.07,0.07,0.1,0.1]\n",
    "\n",
    "    # debug=True means only one lens calculated\n",
    "    nrp = NetworkReweightedPosteriors({\n",
    "        'hypermodel_type':'fixed_param',\n",
    "        'sigmas_log_uniform':False,\n",
    "        'n_emcee_samps':int(6e3)\n",
    "    })\n",
    "\n",
    "    samps_list_seq,weights_list_seq = nrp.reweighted_lens_posteriors_small_number(\n",
    "        y_pred_shifted_seq_list[2],prec_pred_shifted_seq_list[2],train_mean,train_scatter,\n",
    "        seq_reweighted_filepath,\n",
    "        debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that resulting posterior is reasonable...\n",
    "learning_params_names = [r'$\\theta_\\mathrm{E}$',r'$\\gamma_1$',r'$\\gamma_2$',r'$\\gamma_\\mathrm{lens}$',r'$e_1$',\n",
    "\t\t\t\t\t\t\t\tr'$e_2$',r'$x_{lens}$',r'$y_{lens}$',r'$x_{src}$',r'$y_{src}$']\n",
    "i=0\n",
    "\n",
    "snpe_samps = visualization_utils.construct_samps(np.asarray([y_pred_shifted_seq_list[2][i]]),\n",
    "    np.asarray([np.linalg.inv(prec_pred_shifted_seq_list[2][i])]))\n",
    "\n",
    "figure = corner.corner(snpe_samps[:,0,:],bins=20,\n",
    "            show_titles=False,plot_datapoints=False,label_kwargs=dict(fontsize=50),\n",
    "            levels=[0.68,0.95],color='mediumseagreen',fill_contours=True,smooth=1.0)\n",
    "\n",
    "corner.corner(samps_list_seq[i],weights=weights_list_seq[i],bins=20,\n",
    "            show_titles=False,plot_datapoints=False,label_kwargs=dict(fontsize=50),\n",
    "            levels=[0.68,0.95],color='indianred',fill_contours=True,smooth=1.0,\n",
    "            fig=figure,labels=learning_params_names,\n",
    "            truths=y_test_shifted[0],truth_color='black')\n",
    "\n",
    "axes = np.array(figure.axes).reshape((10, 10))\n",
    "custom_lines = [Line2D([0], [0], color='mediumseagreen', lw=4),\n",
    "    Line2D([0], [0], color='indianred', lw=4)]\n",
    "\n",
    "axes[0,9].legend(custom_lines,['SNPE','SNPE-RW'],frameon=False,fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doppelganger Set Reweighting ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_computed = False\n",
    "debug = True\n",
    "\n",
    "if not debug and not already_computed:\n",
    "    print(\"WARNING: Running re-weighting on all 13 doppelganger set lenses takes roughly 30 minutes.\")\n",
    "    print(\"Debug=True ensures this is run for only one lens\")\n",
    "\n",
    "seq_reweighted_filepath = zenodo_filepath+'model_predictions/snpe/doppelganger/reweighted_doppel_shifted.h5'\n",
    "\n",
    "if already_computed == True:\n",
    "    samps_list_seq_shifted,weights_list_seq_shifted = NetworkReweightedPosteriors.load_samps_weights(seq_reweighted_filepath)\n",
    "\n",
    "else:\n",
    "    train_mean = [0.8,0.,0.,2.,0.,0,0.,0.,0.,0.]\n",
    "    train_scatter = [0.15,.12,0.12,0.2,0.2,0.2,0.07,0.07,0.1,0.1]\n",
    "\n",
    "    # debug=True means only one lens calculated\n",
    "    nrp = NetworkReweightedPosteriors({\n",
    "        'hypermodel_type':'fixed_param',\n",
    "        'sigmas_log_uniform':False,\n",
    "        'n_emcee_samps':int(6e3)\n",
    "    })\n",
    "\n",
    "    samps_list_seq,weights_list_seq = nrp.reweighted_lens_posteriors_small_number(\n",
    "        y_pred_doppel_seq_list[2],prec_pred_doppel_seq_list[2],train_mean,train_scatter,\n",
    "        seq_reweighted_filepath,\n",
    "        debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that resulting posterior is reasonable...\n",
    "learning_params_names = [r'$\\theta_\\mathrm{E}$',r'$\\gamma_1$',r'$\\gamma_2$',r'$\\gamma_\\mathrm{lens}$',r'$e_1$',\n",
    "\t\t\t\t\t\t\t\tr'$e_2$',r'$x_{lens}$',r'$y_{lens}$',r'$x_{src}$',r'$y_{src}$']\n",
    "i=0\n",
    "\n",
    "snpe_samps = visualization_utils.construct_samps(np.asarray([y_pred_doppel_seq_list[2][i]]),\n",
    "    np.asarray([np.linalg.inv(prec_pred_doppel_seq_list[2][i])]))\n",
    "\n",
    "figure = corner.corner(snpe_samps[:,0,:],bins=20,\n",
    "            show_titles=False,plot_datapoints=False,label_kwargs=dict(fontsize=50),\n",
    "            levels=[0.68,0.95],color='mediumseagreen',fill_contours=True,smooth=1.0)\n",
    "\n",
    "corner.corner(samps_list_seq[i],weights=weights_list_seq[i],bins=20,\n",
    "            show_titles=False,plot_datapoints=False,label_kwargs=dict(fontsize=50),\n",
    "            levels=[0.68,0.95],color='indianred',fill_contours=True,smooth=1.0,\n",
    "            fig=figure,labels=learning_params_names,\n",
    "            truths=y_test_doppel[0],truth_color='black')\n",
    "\n",
    "axes = np.array(figure.axes).reshape((10, 10))\n",
    "custom_lines = [Line2D([0], [0], color='mediumseagreen', lw=4),\n",
    "    Line2D([0], [0], color='indianred', lw=4)]\n",
    "\n",
    "axes[0,9].legend(custom_lines,['SNPE','SNPE-RW'],frameon=False,fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
