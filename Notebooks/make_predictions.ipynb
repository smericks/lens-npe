{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import h5py\n",
    "from paltas.Utils.distribution_utils import geometric_average\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/smericks/Desktop/StrongLensing/lens-npe/')\n",
    "from network_predictions import NetworkPredictions, generate_sequential_predictions, generate_narrow_sequential_predictions, generate_data_sequential_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to generate network predictions from a trained model. \n",
    "We use the shifted test set for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_filepath = '../Paper/from_zenodo/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPE Predictions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to weights of the trained network\n",
    "path_to_weights = zenodo_filepath+'trained_models/npe/diag/xresnet34_068--14.58.h5'\n",
    "path_to_norms = zenodo_filepath+'trained_models/npe/diag/norms.csv'\n",
    "\n",
    "# which parameters network learned\n",
    "learning_params = ['main_deflector_parameters_theta_E','main_deflector_parameters_gamma1',\n",
    "                   'main_deflector_parameters_gamma2','main_deflector_parameters_gamma',\n",
    "                   'main_deflector_parameters_e1','main_deflector_parameters_e2',\n",
    "                   'main_deflector_parameters_center_x','main_deflector_parameters_center_y',\n",
    "                   'source_parameters_center_x','source_parameters_center_y']\n",
    "learning_params_names = [r'$\\theta_\\mathrm{E}$',r'$\\gamma_1$',r'$\\gamma_2$',r'$\\gamma_\\mathrm{lens}$',r'$e_1$',\n",
    "\t\t\t\t\t\t\t\tr'$e_2$',r'$x_{lens}$',r'$y_{lens}$',r'$x_{src}$',r'$y_{src}$']\n",
    "\n",
    "# set up NetworkPredictions object, uses paltas code to make the predictions\n",
    "predictions = NetworkPredictions(path_to_weights,path_to_norms,\n",
    "    learning_params,loss_type='diag',model_type='xresnet34',norm_type='lognorm')\n",
    "\n",
    "# where to write model predictions\n",
    "write_folder = 'notebook_data/'\n",
    "\n",
    "# where test set images are stored\n",
    "path_to_narrow_set = zenodo_filepath+'test_sets/shifted/'\n",
    "\n",
    "predictions.generate_all_predictions(write_folder,None,path_to_narrow_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating SNPE Training Configs from NPE Predictions ##\n",
    "This is an intermediate step that uses the NPE predictions to generate new\n",
    "training images for SNPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in predictions from broad training\n",
    "file_prefix = 'notebook_data/'\n",
    "file_path = file_prefix+'narrow_predictions.h5'\n",
    "h5f = h5py.File(file_path, 'r')\n",
    "y_pred_narrow = h5f.get('y_pred').value.astype(np.float64)\n",
    "std_pred_narrow = h5f.get('std_pred').value.astype(np.float64)\n",
    "h5f.close()\n",
    "\n",
    "# get rid of scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "mu_prior = np.asarray([0.8,0.,0.,2.0,0.,0.,0.,0.,0.,0.])\n",
    "sigma_prior = np.asarray([0.15,0.12,0.12,0.2,0.2,0.2,0.07,0.07,0.1,0.1])\n",
    "\n",
    "for narrow_idx in range(0,20):\n",
    "\n",
    "    for prior_factor in [2]:\n",
    "\n",
    "        mus = y_pred_narrow[narrow_idx,:]\n",
    "        sigmas = std_pred_narrow[narrow_idx,:]\n",
    "        if prior_factor != 0:\n",
    "            mus,sigmas = geometric_average(mus,sigmas,mu_prior,sigma_prior,weight_wide=prior_factor)\n",
    "            \n",
    "        mus_string = repr(np.round(mus,3))[6:-1]        \n",
    "        sigmas_string = repr(np.round(sigmas,3))[6:-1]\n",
    "\n",
    "        filename = 'notebook_data/sequential_config_base.py'\n",
    "        with open(filename) as file:\n",
    "            lines = [line.rstrip() for line in file]\n",
    "            lines[11] = 'seq_mus = ' + mus_string\n",
    "            lines[12] = 'seq_sigmas = ' + sigmas_string\n",
    "\n",
    "        with open('notebook_data/config_shifted%03d.py'%(narrow_idx), 'w') as f:\n",
    "            for line in lines:\n",
    "                f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNPE Predictions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list is in order 0x,1x,2x,4x\n",
    "y_pred_narrow_seq_list = []\n",
    "std_pred_narrow_seq_list = []\n",
    "prec_pred_narrow_seq_list = []\n",
    "\n",
    "test_set_indices = range(0,20)\n",
    "\n",
    "for f in ['0x','1x','2x','4x']:\n",
    "    epoch = 10\n",
    "    weights_paths = []\n",
    "\n",
    "    #model_weights_list = np.asarray(os.popen('ls -d '+weights_files).read().split())\n",
    "\n",
    "    for i in test_set_indices:\n",
    "        weights_paths.append(zenodo_filepath+'trained_models/snpe/shifted/gem_avg_'\n",
    "            +f+'/xresnet34_%03d_narrow%03d.h5'%(epoch,i))\n",
    "\n",
    "    narrow_image_folder = zenodo_filepath+'test_sets/shifted/'\n",
    "    norm_path = zenodo_filepath+'trained_models/npe/diag/norms.csv'\n",
    "    y_pred_narrow_seq, std_pred_narrow_seq, prec_pred_narrow_seq = generate_narrow_sequential_predictions(\n",
    "        weights_paths,narrow_image_folder,image_indices=test_set_indices,\n",
    "        norms_path=norm_path,loss_type='diag',image_type='h5')\n",
    "    y_pred_narrow_seq_list.append(y_pred_narrow_seq)\n",
    "    std_pred_narrow_seq_list.append(std_pred_narrow_seq)\n",
    "    prec_pred_narrow_seq_list.append(prec_pred_narrow_seq)\n",
    "\n",
    "y_pred_narrow_seq_list = np.asarray(y_pred_narrow_seq_list)\n",
    "std_pred_narrow_seq_list = np.asarray(std_pred_narrow_seq_list)\n",
    "\n",
    "np.save('notebook_data/y_pred_list_epoch10.npy',\n",
    "    y_pred_narrow_seq_list)\n",
    "np.save('notebook_data/std_pred_list_epoch10.npy',\n",
    "        std_pred_narrow_seq_list)\n",
    "np.save('notebook_data/prec_pred_list_epoch10.npy',\n",
    "        prec_pred_narrow_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
